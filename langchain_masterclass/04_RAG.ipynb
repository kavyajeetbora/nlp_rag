{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP9/diakSp9C25cADad99n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/nlp_rag/blob/master/langchain_masterclass/04_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG - Retrieval Augmented Generated\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is an AI framework that enhances the accuracy and relevance of responses generated by large language models (LLMs). It combines two techniques:\n",
        "\n",
        "1. Retrieval: The model first retrieves relevant information from external sources, such as databases, documents, or the web.\n",
        "2. Generation: It then uses this retrieved information to inform and enhance the generation of responses.\n",
        "\n",
        "This approach ensures that the responses are accurate, relevant, and contextually enriched by the most up-to-date and specific information available2. RAG is particularly useful for creating more reliable and effective AI systems across various applications"
      ],
      "metadata": {
        "id": "V6W0uI0yZoPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "hiqUmqwLmoj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTK7tlp1qc7B",
        "outputId": "4cf0fa09-0396-48ce-ae84-28644379e86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_community langchain-openai chromadb randomname"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import randomname\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "y5CQ__6Hq7SM"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\".env\"):\n",
        "    os.remove(\".env\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    if load_dotenv(\".env\"):\n",
        "        print(\"Uploaded and Loaded Sucessfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "dg40UC0iq47h",
        "outputId": "c6138247-3952-4267-be25-69ce0282930f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43917164-0e6c-4206-9965-4da682487a25\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43917164-0e6c-4206-9965-4da682487a25\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env\n",
            "Uploaded and Loaded Sucessfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load LLM Model"
      ],
      "metadata": {
        "id": "A62umtqwtTDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model='gpt-3.5-turbo-0125')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC2OigdescDJ",
        "outputId": "a7e3ca27-0503-42c2-f9a7-bb9866353b97"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7b875a7bada0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b875a7a83a0>, root_client=<openai.OpenAI object at 0x7b8727724c40>, root_async_client=<openai.AsyncOpenAI object at 0x7b875a7b8b50>, model_name='gpt-3.5-turbo-0125', model_kwargs={}, openai_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High level RAG Pipeline using LangChain"
      ],
      "metadata": {
        "id": "hf95_V5bZ9Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the source text"
      ],
      "metadata": {
        "id": "tp9f4odiaTgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/kavyajeetbora/nlp_rag/refs/heads/master/data/taare_zameen_par.txt -O taare_zameen_par.txt\n",
        "!wget -q https://raw.githubusercontent.com/kavyajeetbora/nlp_rag/refs/heads/master/data/swades.txt -O swades.txt\n",
        "!wget -q https://raw.githubusercontent.com/kavyajeetbora/nlp_rag/refs/heads/master/data/munna_bhai.txt -O munna_bhai.txt\n",
        "!wget -q https://raw.githubusercontent.com/kavyajeetbora/nlp_rag/refs/heads/master/data/lagaan.txt -O lagaan.txt"
      ],
      "metadata": {
        "id": "nuQFERGsznnl"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file_path = \"taare_zameen_par.txt\"\n",
        "\n",
        "if os.path.exists(text_file_path):\n",
        "    loader = TextLoader(text_file_path)\n",
        "    documents = loader.load()\n",
        "    print(\"Source Document Loaded Sucessfully\")\n",
        "else:\n",
        "    print(f\"No file called {text_file_path} found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi-yAyyNaSIZ",
        "outputId": "ca0b38e9-abf5-49c9-e8a7-bc4d8567c394"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Document Loaded Sucessfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pueGutvUflhk",
        "outputId": "74b82a17-bf4b-4be0-aa98-6f4b6adf6502"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'taare_zameen_par.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the text into Chunks\n",
        "\n",
        "Why chunking? as we know there is limited number of characters/tokens we can pass on to our LLM model for generation. So we need to break down our large chunk of text into smaller consumable pieces"
      ],
      "metadata": {
        "id": "kn0tB4u4f80O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(separator = \" \", chunk_size=300, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmb-x4K_gLbd",
        "outputId": "65ea3bc6-cc72-431f-ce82-54849b4a4ee7"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Here is the first chunk\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWvM4bSogp8D",
        "outputId": "3848d8d4-48c6-4c70-b1dc-c78099884afb"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'taare_zameen_par.txt'}, page_content=\"Ishaan is an 8-year-old boy living in Mumbai, who has trouble following school. He is assumed by all to simply hate learning and deemed a troublemaker, and is belittled for it. He has even repeated the 3rd standard due to his academic failures from the previous year. Ishaan's imagination,\")"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Embedding Model\n",
        "\n",
        "Embedding models are mostly encoder based model (for example BERT and RoBERTa architecture)\n",
        "\n",
        "Here is a brief of encoder only models:\n",
        "\n",
        "1. An encoder-only model is a type of machine learning model that focuses on understanding text, but doesn't generate new text:\n",
        "2. What they do ?\n",
        "\n",
        "    Encoder-only models are designed to analyze the meaning of words and sentences in a text, and produce task-specific outputs like labels or token predictions.\n",
        "3. What they're good for?\n",
        "\n",
        "    They're well-suited for tasks that require understanding text, like text classification, question answering, and sentiment analysis.\n",
        "4. How they work\n",
        "    \n",
        "    Encoder-only models process input text in a bidirectional manner, considering the context of each word from both the left and right sides. This allows them to understand the full meaning of a text.\n",
        "5. Examples\n",
        "    \n",
        "    BERT (Bidirectional Encoder Representations from Transformers) and RoBERTa are examples of encoder-only models.\n",
        "\n",
        "Encoder-only models are different from decoder-only models, which are used for other types of generative tasks like Q&A"
      ],
      "metadata": {
        "id": "zYWEgRRmhNce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
      ],
      "metadata": {
        "id": "b-Zli62Ykb7-"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Vector Database\n",
        "\n",
        "We will store all the embeddings from the source in Vector Database.\n",
        "\n",
        "We will use [`langchain_community.Chroma.from_documents`](https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.from_documents)"
      ],
      "metadata": {
        "id": "9tfkvsGAdwm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"db\", exist_ok=True)\n",
        "\n",
        "random_suffix = randomname.get_name()\n",
        "\n",
        "persistent_directory = f\"db/chroma-({random_suffix})\"\n",
        "\n",
        "## If already there, delete and create a new one\n",
        "for folder in glob(\"db/chroma*\"):\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "\n",
        "os.mkdir(persistent_directory)\n",
        "\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents = docs,\n",
        "    collection_name = \"movie_embeddings_v1\",\n",
        "    embedding = embeddings,\n",
        "    persist_directory = persistent_directory\n",
        ")"
      ],
      "metadata": {
        "id": "utfrRaoJdQPi"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving Relevant Chunks based on a query"
      ],
      "metadata": {
        "id": "0LMvOaNqvWGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was Ishaan ?\"\n",
        "\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type = \"similarity_score_threshold\",\n",
        "    search_kwargs = {\"k\": 2, \"score_threshold\": 0.5}\n",
        ")\n",
        "\n",
        "relevant_docs = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "vjDNAIylmDs3"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in relevant_docs:\n",
        "    print(\"Source:\",doc.metadata['source'])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2p0eNYNv6lq",
        "outputId": "3d74a326-a722-4f8f-fc8f-94ff120bdf90"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: taare_zameen_par.txt\n",
            "Ishaan is an 8-year-old boy living in Mumbai, who has trouble following school. He is assumed by all to simply hate learning and deemed a troublemaker, and is belittled for it. He has even repeated the 3rd standard due to his academic failures from the previous year. Ishaan's imagination,\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Metadata for documents\n",
        "\n",
        "while embedding the documents, it is always a good idea to add metadata to each document like adding title, filename, filesize, pages, author etc etc\n",
        "\n",
        "This is important when retrieving any document as we may want to know the reference when our LLM is generating any text for validation purpose"
      ],
      "metadata": {
        "id": "x06lBZg9zCWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a vector database from many documents\n",
        "documents = []\n",
        "for txt_file_path in glob(\"*.txt\"):\n",
        "\n",
        "    loader = TextLoader(txt_file_path)\n",
        "    docs = loader.load()\n",
        "\n",
        "    for doc in docs:\n",
        "        doc.metadata = {\"soure\": txt_file_path}\n",
        "        documents.append(doc)"
      ],
      "metadata": {
        "id": "XLkPva-jzB8b"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the documents into chunks\n",
        "text_splitter = CharacterTextSplitter(separator=\" \", chunk_size=500, chunk_overlap=0)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h72cO89t1YHj",
        "outputId": "1e5191bf-532c-43b9-a392-242cdb2a1e6a"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUq2Huju2Ul8",
        "outputId": "5ff82fed-d4d1-4007-e0af-3d7e81f7561b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "494"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"db\", exist_ok=True)\n",
        "\n",
        "random_suffix = randomname.get_name()\n",
        "\n",
        "persistent_directory = f\"db/chroma-({random_suffix})\"\n",
        "\n",
        "## If already there, delete and create a new one\n",
        "for folder in glob(\"db/chroma*\"):\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "\n",
        "os.mkdir(persistent_directory)\n",
        "\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents = chunks,\n",
        "    collection_name = \"movie_embeddings_v2\",\n",
        "    embedding = embeddings,\n",
        "    persist_directory = persistent_directory\n",
        ")"
      ],
      "metadata": {
        "id": "3w1xSgQW2dGj"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrive the text using a query:"
      ],
      "metadata": {
        "id": "tZXoPON024aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_db.as_retriever(\n",
        "    search_type = \"similarity_score_threshold\",\n",
        "    search_kwargs = {\"k\": 3, \"score_threshold\": 0.1}\n",
        ")"
      ],
      "metadata": {
        "id": "E_crZzrC23r3"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Explain the character of Munna\"\n",
        "retriever.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihlh0X-m3pRC",
        "outputId": "ad90cbaa-5cd1-452a-b00e-ea5fba2fcc6b"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'soure': 'munna_bhai.txt'}, page_content='and forgive him. Munna ends up marrying Suman after learning of her true identity as \"Chinki\", and together, they open a real hospital in Munna\\'s family village. Circuit also gets married a year later and has a son nicknamed \"Short Circuit\". Asthana resigns as the dean and becomes the head doctor, employing Munna\\'s methods, while Rustom succeeds him. As the film concludes, Anand, restored to normal mental health, narrates the story to a few children at the hospital as he is about to leave for'),\n",
              " Document(metadata={'soure': 'munna_bhai.txt'}, page_content=\"Munna Bhai film series, the film follows Munna Bhai, a don in the Mumbai underworld, trying to please his father by pretending to be a doctor, but when a doctor, Asthana (Irani), exposes his lies and tarnishes his father's honor, Munna enrolls in a medical college. Chaos ensues when Munna, upon finding that Asthana is the dean of the college, vows revenge, while also sparking a romance with a house doctor, Suman (Singh), unaware that she is his childhood friend and Asthana's daughter. The film\"),\n",
              " Document(metadata={'soure': 'munna_bhai.txt'}, page_content='patients, especially those who are deemed incurable by conventional medicine. His behavior is well-received by the hospital staff and patients, who are able to see the good-natured intent behind his anti-establishment actions. Asthana, perceiving this as chaos, is unable to stop it and resorts to laughter therapy to deal with his stress.\\n\\nMunna simultaneously develops a friendly relationship with Dr. Suman, who works at the hospital, unaware that she is \"Chinki\", an ignorance she hilariously')]"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"A.R Rahman composed the music of which movies ?\"\n",
        "retriever.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBXr4fz33sjp",
        "outputId": "44320d6c-e029-440c-ffd8-ea56b040ddcf"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'soure': 'swades.txt'}, page_content='was composed by A. R. Rahman, with lyrics penned by Javed Akhtar.\\n\\nSwades was theatrically released on 17 December 2004, and it opened to rave reviews from critics, with praise for the performances of Khan, Joshi and Ballal, and the story, screenplay, and soundtrack. However, it emerged as a commercial failure at the box office.\\n\\nAt the 50th Filmfare Awards, Swades received 8 nominations, including Best Film, Best Director (Gowarikar) and Best Music Director (Rahman), and won Best Actor (Khan)'),\n",
              " Document(metadata={'soure': 'swades.txt'}, page_content=\"and Best Background Score (Rahman).\\n\\nIt was dubbed in Tamil as Desam and released on 26 January 2005, coinciding with Indian Republic Day. Despite its commercial failure, Swades is regarded ahead of its time and is now considered a cult classic of Hindi cinema and one of the best films in Shah Rukh Khan's filmography. [10][11] The film is owned by Red Chillies Entertainment.[12]\\n\\nPlot\\nMohan Bhargava is a non-resident Indian who works as a Project Manager on the Global Precipitation Measurement\"),\n",
              " Document(metadata={'soure': 'lagaan.txt'}, page_content=\"director, while Bhanu Athaiya was the costume designer. The original soundtrack was composed by A. R. Rahman, with lyrics written by Javed Akhtar.\\n\\nLagaan was theatrically released in India on 15 June 2001, clashing with Gadar: Ek Prem Katha. It received widespread critical acclaim for Gowariker's direction, Khan's performance, dialogues, soundtrack, and the film's anti-imperialist stance. With earnings of ₹65.97 crore (US$13.98 million) during its initial release, the film was the third\")]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"In which movies the director was Ashutosh Gowariker ?\"\n",
        "retriever.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D8fgEw932ib",
        "outputId": "f8418b58-b6f6-4a7e-e045-3c3d83a6d20d"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'soure': 'lagaan.txt'}, page_content='Lagaan: Once Upon a Time in India, or simply Lagaan, (transl.\\u2009Land tax) is a 2001 Indian Hindi-language epic period musical[5] sports drama film written and directed by Ashutosh Gowariker. The film was produced by Aamir Khan, who stars alongside debutant Gracy Singh and British actors Rachel Shelley and Paul Blackthorne. Set in 1893, during the late Victorian period of British colonial rule in India, the film follows the inhabitants of a village in Central India, who, burdened by high taxes and'),\n",
              " Document(metadata={'soure': 'swades.txt'}, page_content=\"Swades: We, the People (transl.\\u2009Homeland) is a 2004 Indian Hindi-language drama film co-written, directed and produced by Ashutosh Gowariker.[3] The film stars Shah Rukh Khan, Gayatri Joshi and Kishori Ballal while Daya Shankar Pandey, Rajesh Vivek, Lekh Tandon appear in supporting roles.\\n\\nThe plot was based on two episodes of the series Vaapsi on Zee TV's Yule Love Stories (1994–95) which had Gowariker playing the role of Mohan Bhargav.[4] The story of the lead role setting up a micro\"),\n",
              " Document(metadata={'soure': 'lagaan.txt'}, page_content=\"prospective producers called for budget cuts and script modifications. Eventually, the film would become the maiden project of Aamir Khan Productions, and mark Khan's foray into film production. Gowariker was inspired by aspects of sports drama Naya Daur (1957) in developing the film. The language featured in the film was based on Awadhi, but was diluted with standard Hindi for modern audiences. Principal photography took place in villages near Bhuj. Nitin Chandrakant Desai served as art\")]"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    }
  ]
}